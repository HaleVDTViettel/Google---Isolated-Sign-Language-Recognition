{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.model_selection import StratifiedGroupKFold, KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>row_id</th>\n",
       "      <th>type</th>\n",
       "      <th>landmark_index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20-face-0</td>\n",
       "      <td>face</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.380470</td>\n",
       "      <td>-0.030626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>20-face-1</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496017</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>-0.057565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>20-face-2</td>\n",
       "      <td>face</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500818</td>\n",
       "      <td>0.359343</td>\n",
       "      <td>-0.030283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>20-face-3</td>\n",
       "      <td>face</td>\n",
       "      <td>3</td>\n",
       "      <td>0.489788</td>\n",
       "      <td>0.321780</td>\n",
       "      <td>-0.040622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>20-face-4</td>\n",
       "      <td>face</td>\n",
       "      <td>4</td>\n",
       "      <td>0.495304</td>\n",
       "      <td>0.341821</td>\n",
       "      <td>-0.061152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12484</th>\n",
       "      <td>42</td>\n",
       "      <td>42-right_hand-16</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.549574</td>\n",
       "      <td>-0.145409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12485</th>\n",
       "      <td>42</td>\n",
       "      <td>42-right_hand-17</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>17</td>\n",
       "      <td>0.042694</td>\n",
       "      <td>0.693116</td>\n",
       "      <td>-0.085307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>42</td>\n",
       "      <td>42-right_hand-18</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>18</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.665044</td>\n",
       "      <td>-0.114017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>42</td>\n",
       "      <td>42-right_hand-19</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.014755</td>\n",
       "      <td>0.643799</td>\n",
       "      <td>-0.123488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>42</td>\n",
       "      <td>42-right_hand-20</td>\n",
       "      <td>right_hand</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.031811</td>\n",
       "      <td>0.627077</td>\n",
       "      <td>-0.129067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12489 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame            row_id        type  landmark_index         x  \\\n",
       "0         20         20-face-0        face               0  0.494400   \n",
       "1         20         20-face-1        face               1  0.496017   \n",
       "2         20         20-face-2        face               2  0.500818   \n",
       "3         20         20-face-3        face               3  0.489788   \n",
       "4         20         20-face-4        face               4  0.495304   \n",
       "...      ...               ...         ...             ...       ...   \n",
       "12484     42  42-right_hand-16  right_hand              16  0.001660   \n",
       "12485     42  42-right_hand-17  right_hand              17  0.042694   \n",
       "12486     42  42-right_hand-18  right_hand              18  0.006723   \n",
       "12487     42  42-right_hand-19  right_hand              19 -0.014755   \n",
       "12488     42  42-right_hand-20  right_hand              20 -0.031811   \n",
       "\n",
       "              y         z  \n",
       "0      0.380470 -0.030626  \n",
       "1      0.350735 -0.057565  \n",
       "2      0.359343 -0.030283  \n",
       "3      0.321780 -0.040622  \n",
       "4      0.341821 -0.061152  \n",
       "...         ...       ...  \n",
       "12484  0.549574 -0.145409  \n",
       "12485  0.693116 -0.085307  \n",
       "12486  0.665044 -0.114017  \n",
       "12487  0.643799 -0.123488  \n",
       "12488  0.627077 -0.129067  \n",
       "\n",
       "[12489 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('train_landmark_files/26734/1000035562.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "face          468\n",
       "pose           33\n",
       "left_hand      21\n",
       "right_hand     21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:543].type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "face          468\n",
       "pose           33\n",
       "left_hand      21\n",
       "right_hand     21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[543:543*2].type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ROWS_PER_FRAME = 543\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('sign_to_prediction_index_map.json') as json_file:\n",
    "    LABEL_DICT = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TV': 0,\n",
       " 'after': 1,\n",
       " 'airplane': 2,\n",
       " 'all': 3,\n",
       " 'alligator': 4,\n",
       " 'animal': 5,\n",
       " 'another': 6,\n",
       " 'any': 7,\n",
       " 'apple': 8,\n",
       " 'arm': 9,\n",
       " 'aunt': 10,\n",
       " 'awake': 11,\n",
       " 'backyard': 12,\n",
       " 'bad': 13,\n",
       " 'balloon': 14,\n",
       " 'bath': 15,\n",
       " 'because': 16,\n",
       " 'bed': 17,\n",
       " 'bedroom': 18,\n",
       " 'bee': 19,\n",
       " 'before': 20,\n",
       " 'beside': 21,\n",
       " 'better': 22,\n",
       " 'bird': 23,\n",
       " 'black': 24,\n",
       " 'blow': 25,\n",
       " 'blue': 26,\n",
       " 'boat': 27,\n",
       " 'book': 28,\n",
       " 'boy': 29,\n",
       " 'brother': 30,\n",
       " 'brown': 31,\n",
       " 'bug': 32,\n",
       " 'bye': 33,\n",
       " 'callonphone': 34,\n",
       " 'can': 35,\n",
       " 'car': 36,\n",
       " 'carrot': 37,\n",
       " 'cat': 38,\n",
       " 'cereal': 39,\n",
       " 'chair': 40,\n",
       " 'cheek': 41,\n",
       " 'child': 42,\n",
       " 'chin': 43,\n",
       " 'chocolate': 44,\n",
       " 'clean': 45,\n",
       " 'close': 46,\n",
       " 'closet': 47,\n",
       " 'cloud': 48,\n",
       " 'clown': 49,\n",
       " 'cow': 50,\n",
       " 'cowboy': 51,\n",
       " 'cry': 52,\n",
       " 'cut': 53,\n",
       " 'cute': 54,\n",
       " 'dad': 55,\n",
       " 'dance': 56,\n",
       " 'dirty': 57,\n",
       " 'dog': 58,\n",
       " 'doll': 59,\n",
       " 'donkey': 60,\n",
       " 'down': 61,\n",
       " 'drawer': 62,\n",
       " 'drink': 63,\n",
       " 'drop': 64,\n",
       " 'dry': 65,\n",
       " 'dryer': 66,\n",
       " 'duck': 67,\n",
       " 'ear': 68,\n",
       " 'elephant': 69,\n",
       " 'empty': 70,\n",
       " 'every': 71,\n",
       " 'eye': 72,\n",
       " 'face': 73,\n",
       " 'fall': 74,\n",
       " 'farm': 75,\n",
       " 'fast': 76,\n",
       " 'feet': 77,\n",
       " 'find': 78,\n",
       " 'fine': 79,\n",
       " 'finger': 80,\n",
       " 'finish': 81,\n",
       " 'fireman': 82,\n",
       " 'first': 83,\n",
       " 'fish': 84,\n",
       " 'flag': 85,\n",
       " 'flower': 86,\n",
       " 'food': 87,\n",
       " 'for': 88,\n",
       " 'frenchfries': 89,\n",
       " 'frog': 90,\n",
       " 'garbage': 91,\n",
       " 'gift': 92,\n",
       " 'giraffe': 93,\n",
       " 'girl': 94,\n",
       " 'give': 95,\n",
       " 'glasswindow': 96,\n",
       " 'go': 97,\n",
       " 'goose': 98,\n",
       " 'grandma': 99,\n",
       " 'grandpa': 100,\n",
       " 'grass': 101,\n",
       " 'green': 102,\n",
       " 'gum': 103,\n",
       " 'hair': 104,\n",
       " 'happy': 105,\n",
       " 'hat': 106,\n",
       " 'hate': 107,\n",
       " 'have': 108,\n",
       " 'haveto': 109,\n",
       " 'head': 110,\n",
       " 'hear': 111,\n",
       " 'helicopter': 112,\n",
       " 'hello': 113,\n",
       " 'hen': 114,\n",
       " 'hesheit': 115,\n",
       " 'hide': 116,\n",
       " 'high': 117,\n",
       " 'home': 118,\n",
       " 'horse': 119,\n",
       " 'hot': 120,\n",
       " 'hungry': 121,\n",
       " 'icecream': 122,\n",
       " 'if': 123,\n",
       " 'into': 124,\n",
       " 'jacket': 125,\n",
       " 'jeans': 126,\n",
       " 'jump': 127,\n",
       " 'kiss': 128,\n",
       " 'kitty': 129,\n",
       " 'lamp': 130,\n",
       " 'later': 131,\n",
       " 'like': 132,\n",
       " 'lion': 133,\n",
       " 'lips': 134,\n",
       " 'listen': 135,\n",
       " 'look': 136,\n",
       " 'loud': 137,\n",
       " 'mad': 138,\n",
       " 'make': 139,\n",
       " 'man': 140,\n",
       " 'many': 141,\n",
       " 'milk': 142,\n",
       " 'minemy': 143,\n",
       " 'mitten': 144,\n",
       " 'mom': 145,\n",
       " 'moon': 146,\n",
       " 'morning': 147,\n",
       " 'mouse': 148,\n",
       " 'mouth': 149,\n",
       " 'nap': 150,\n",
       " 'napkin': 151,\n",
       " 'night': 152,\n",
       " 'no': 153,\n",
       " 'noisy': 154,\n",
       " 'nose': 155,\n",
       " 'not': 156,\n",
       " 'now': 157,\n",
       " 'nuts': 158,\n",
       " 'old': 159,\n",
       " 'on': 160,\n",
       " 'open': 161,\n",
       " 'orange': 162,\n",
       " 'outside': 163,\n",
       " 'owie': 164,\n",
       " 'owl': 165,\n",
       " 'pajamas': 166,\n",
       " 'pen': 167,\n",
       " 'pencil': 168,\n",
       " 'penny': 169,\n",
       " 'person': 170,\n",
       " 'pig': 171,\n",
       " 'pizza': 172,\n",
       " 'please': 173,\n",
       " 'police': 174,\n",
       " 'pool': 175,\n",
       " 'potty': 176,\n",
       " 'pretend': 177,\n",
       " 'pretty': 178,\n",
       " 'puppy': 179,\n",
       " 'puzzle': 180,\n",
       " 'quiet': 181,\n",
       " 'radio': 182,\n",
       " 'rain': 183,\n",
       " 'read': 184,\n",
       " 'red': 185,\n",
       " 'refrigerator': 186,\n",
       " 'ride': 187,\n",
       " 'room': 188,\n",
       " 'sad': 189,\n",
       " 'same': 190,\n",
       " 'say': 191,\n",
       " 'scissors': 192,\n",
       " 'see': 193,\n",
       " 'shhh': 194,\n",
       " 'shirt': 195,\n",
       " 'shoe': 196,\n",
       " 'shower': 197,\n",
       " 'sick': 198,\n",
       " 'sleep': 199,\n",
       " 'sleepy': 200,\n",
       " 'smile': 201,\n",
       " 'snack': 202,\n",
       " 'snow': 203,\n",
       " 'stairs': 204,\n",
       " 'stay': 205,\n",
       " 'sticky': 206,\n",
       " 'store': 207,\n",
       " 'story': 208,\n",
       " 'stuck': 209,\n",
       " 'sun': 210,\n",
       " 'table': 211,\n",
       " 'talk': 212,\n",
       " 'taste': 213,\n",
       " 'thankyou': 214,\n",
       " 'that': 215,\n",
       " 'there': 216,\n",
       " 'think': 217,\n",
       " 'thirsty': 218,\n",
       " 'tiger': 219,\n",
       " 'time': 220,\n",
       " 'tomorrow': 221,\n",
       " 'tongue': 222,\n",
       " 'tooth': 223,\n",
       " 'toothbrush': 224,\n",
       " 'touch': 225,\n",
       " 'toy': 226,\n",
       " 'tree': 227,\n",
       " 'uncle': 228,\n",
       " 'underwear': 229,\n",
       " 'up': 230,\n",
       " 'vacuum': 231,\n",
       " 'wait': 232,\n",
       " 'wake': 233,\n",
       " 'water': 234,\n",
       " 'wet': 235,\n",
       " 'weus': 236,\n",
       " 'where': 237,\n",
       " 'white': 238,\n",
       " 'who': 239,\n",
       " 'why': 240,\n",
       " 'will': 241,\n",
       " 'wolf': 242,\n",
       " 'yellow': 243,\n",
       " 'yes': 244,\n",
       " 'yesterday': 245,\n",
       " 'yourself': 246,\n",
       " 'yucky': 247,\n",
       " 'zebra': 248,\n",
       " 'zipper': 249}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_row(row):\n",
    "    coordinates = load_relevant_data_subset(f'{row.path}')\n",
    "    coordinates_encoded = coordinates.tobytes()\n",
    "    participant_id = int(row.participant_id)\n",
    "    sequence_id = int(row.sequence_id)\n",
    "    sign = int(LABEL_DICT[row.sign])\n",
    "    record_bytes = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'coordinates': tf.train.Feature(bytes_list=tf.train.BytesList(value=[coordinates_encoded])),\n",
    "                'participant_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[participant_id])),\n",
    "                'sequence_id':tf.train.Feature(int64_list=tf.train.Int64List(value=[sequence_id])),\n",
    "                'sign':tf.train.Feature(int64_list=tf.train.Int64List(value=[sign])),\n",
    "                })).SerializeToString()\n",
    "    return record_bytes\n",
    "\n",
    "def process_chunk(chunk, tfrecord_name):\n",
    "    options = tf.io.TFRecordOptions(compression_type='GZIP', compression_level=9)\n",
    "    with tf.io.TFRecordWriter(tfrecord_name, options=options) as file_writer:\n",
    "        for i, row in tqdm(chunk.iterrows()):\n",
    "            record_bytes = encode_row(row)\n",
    "            file_writer.write(record_bytes)\n",
    "            del record_bytes\n",
    "        file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_df.iloc[0]\n",
    "coordinates = load_relevant_data_subset(f'{row.path}')\n",
    "coordinates_encoded = coordinates.tobytes()\n",
    "participant_id = int(row.participant_id)\n",
    "sequence_id = int(row.sequence_id)\n",
    "sign = int(LABEL_DICT[row.sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_bytes = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'coordinates': tf.train.Feature(bytes_list=tf.train.BytesList(value=[coordinates_encoded])),\n",
    "            'participant_id': tf.train.Feature(int64_list=tf.train.Int64List(value=[participant_id])),\n",
    "            'sequence_id':tf.train.Feature(int64_list=tf.train.Int64List(value=[sequence_id])),\n",
    "            'sign':tf.train.Feature(int64_list=tf.train.Int64List(value=[sign])),\n",
    "            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILES = len(train_df)\n",
    "CHUNK_SIZE = 512\n",
    "N_PART = 1\n",
    "FOLD = 4\n",
    "part = 0\n",
    "\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    n_splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4fold training 94477 samples\n",
      "fold0: train 70857 valid 23620\n",
      "fold1: train 70858 valid 23619\n",
      "fold2: train 70858 valid 23619\n",
      "fold3: train 70858 valid 23619\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign  fold  \n",
       "0   blow     1  \n",
       "1   wait     2  \n",
       "2  cloud     3  \n",
       "3   bird     2  \n",
       "4   owie     1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds = train_df.copy()\n",
    "train_folds['fold']=-1\n",
    "\n",
    "num_bins = 5\n",
    "\n",
    "# train_folds = train_folds.sample(frac=1, random_state=CFG.seed).reset_index(drop=True)\n",
    "# gkfold = StratifiedGroupKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed) \n",
    "# print(f'{CFG.n_splits}fold training', len(train_folds), 'samples')\n",
    "# for fold_idx, (train_idx, valid_idx) in enumerate(gkfold.split(train_folds, y=train_folds['sign'].values, groups=train_folds.participant_id)):\n",
    "#     train_folds.loc[valid_idx,'fold'] = fold_idx\n",
    "#     print(f'fold{fold_idx}:', 'train', len(train_idx), 'valid', len(valid_idx))\n",
    "kfold = KFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed) \n",
    "print(f'{CFG.n_splits}fold training', len(train_folds), 'samples')\n",
    "for fold_idx, (train_idx, valid_idx) in enumerate(kfold.split(train_folds)):\n",
    "    train_folds.loc[valid_idx,'fold'] = fold_idx\n",
    "    print(f'fold{fold_idx}:', 'train', len(train_idx), 'valid', len(valid_idx))\n",
    "    \n",
    "assert not (train_folds['fold']==-1).sum()\n",
    "assert len(np.unique(train_folds['fold']))==CFG.n_splits\n",
    "train_folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put every image in a seperate TFRecord file\n",
    "# Make Pairs of Views as input to the model\n",
    "import json\n",
    "import os\n",
    "\n",
    "DATASET_NAME = f'ISLR-{CFG.n_splits}fold-randsplit'\n",
    "\n",
    "!rm -rf tmp/{DATASET_NAME}\n",
    "\n",
    "os.makedirs(f'tmp/{DATASET_NAME}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "512it [00:06, 81.59it/s] \n",
      "512it [00:06, 83.07it/s]\n",
      "512it [00:06, 81.66it/s]\n",
      "512it [00:06, 81.16it/s]\n",
      "512it [00:06, 79.55it/s]\n",
      "512it [00:06, 80.33it/s]\n",
      "512it [00:06, 82.82it/s]\n",
      "512it [00:06, 79.70it/s]\n",
      "512it [00:05, 86.02it/s]\n",
      "512it [00:06, 79.41it/s]\n",
      "512it [00:06, 78.89it/s]\n",
      "512it [00:06, 78.26it/s]\n",
      "512it [00:06, 82.33it/s]\n",
      "512it [00:06, 83.53it/s]\n",
      "512it [00:06, 80.13it/s]\n",
      "512it [00:06, 81.39it/s]\n",
      "512it [00:06, 78.86it/s]\n",
      "512it [00:06, 77.64it/s]\n",
      "512it [00:07, 72.35it/s]\n",
      "512it [00:06, 75.49it/s]\n",
      "512it [00:06, 82.12it/s]]\n",
      "512it [00:06, 79.67it/s]]\n",
      "512it [00:06, 83.68it/s] \n",
      "512it [00:06, 81.12it/s] \n",
      "512it [00:06, 80.35it/s]\n",
      "512it [00:06, 80.15it/s]\n",
      "512it [00:06, 80.14it/s]\n",
      "512it [00:06, 83.45it/s]\n",
      "512it [00:06, 83.40it/s]\n",
      "512it [00:06, 80.37it/s]\n",
      "512it [00:06, 83.65it/s]\n",
      "512it [00:06, 78.44it/s]\n",
      "512it [00:06, 80.09it/s]\n",
      "512it [00:06, 76.99it/s]\n",
      "512it [00:06, 84.52it/s]\n",
      "512it [00:06, 80.17it/s]\n",
      "512it [00:06, 83.93it/s]\n",
      "512it [00:06, 75.41it/s]\n",
      "68it [00:00, 87.61it/s]]\n",
      "512it [00:06, 76.11it/s]\n",
      "512it [00:06, 75.94it/s]]\n",
      "512it [00:04, 112.99it/s]\n",
      "512it [00:04, 111.03it/s]\n",
      "512it [00:04, 110.00it/s]\n",
      "512it [00:04, 108.53it/s]\n",
      "512it [00:04, 106.22it/s]\n",
      "512it [00:05, 97.27it/s] \n",
      "512it [00:06, 82.37it/s] \n",
      "512it [00:06, 82.52it/s]\n",
      "512it [00:06, 80.87it/s]\n",
      "512it [00:06, 79.82it/s]\n",
      "512it [00:06, 79.53it/s]\n",
      "512it [00:06, 79.25it/s]\n",
      "512it [00:06, 78.81it/s]\n",
      "512it [00:06, 78.63it/s]\n",
      "512it [00:06, 78.40it/s]\n",
      "512it [00:06, 78.26it/s]\n",
      "512it [00:06, 77.49it/s]\n",
      "512it [00:06, 77.92it/s]\n",
      "512it [00:06, 77.56it/s]\n",
      "512it [00:06, 76.51it/s]\n",
      "512it [00:06, 76.58it/s]\n",
      "512it [00:06, 75.30it/s]\n",
      "512it [00:06, 74.91it/s]\n",
      "512it [00:06, 74.75it/s]\n",
      "512it [00:07, 72.87it/s]\n",
      "512it [00:07, 71.74it/s]\n",
      "512it [00:06, 78.81it/s] \n",
      "512it [00:06, 80.59it/s]\n",
      "512it [00:06, 77.68it/s]\n",
      "512it [00:06, 74.33it/s]\n",
      "512it [00:06, 74.39it/s]\n",
      "512it [00:06, 74.33it/s]\n",
      "512it [00:07, 71.66it/s]\n",
      "512it [00:06, 75.30it/s]\n",
      "512it [00:06, 75.85it/s]\n",
      "512it [00:07, 72.91it/s]\n",
      "512it [00:06, 76.56it/s]\n",
      "512it [00:07, 72.34it/s]\n",
      "512it [00:06, 74.18it/s]\n",
      "512it [00:06, 77.42it/s]\n",
      "512it [00:07, 71.47it/s]\n",
      "512it [00:07, 70.52it/s]\n",
      "512it [00:07, 70.45it/s]\n",
      "512it [00:07, 72.71it/s]\n",
      "512it [00:06, 74.35it/s]\n",
      "512it [00:07, 70.52it/s]\n",
      "67it [00:01, 60.45it/s]]\n",
      "512it [00:05, 98.44it/s] \n",
      "512it [00:04, 107.18it/s]\n",
      "512it [00:05, 98.55it/s] \n",
      "512it [00:04, 107.15it/s]\n",
      "512it [00:05, 95.96it/s] \n",
      "512it [00:05, 99.70it/s] \n",
      "512it [00:06, 84.37it/s] \n",
      "512it [00:06, 81.95it/s]\n",
      "512it [00:06, 79.51it/s]\n",
      "512it [00:06, 79.08it/s]\n",
      "512it [00:06, 79.00it/s]\n",
      "512it [00:06, 79.01it/s]\n",
      "512it [00:06, 78.29it/s]\n",
      "512it [00:06, 77.16it/s]\n",
      "512it [00:06, 77.02it/s]\n",
      "\n",
      "512it [00:06, 76.36it/s]\n",
      "512it [00:06, 76.04it/s]\n",
      "512it [00:06, 75.59it/s]\n",
      "512it [00:06, 75.28it/s]\n",
      "512it [00:06, 75.16it/s]\n",
      "512it [00:06, 73.87it/s]\n",
      "512it [00:06, 74.02it/s]\n",
      "512it [00:07, 72.61it/s]\n",
      "512it [00:07, 72.39it/s]\n",
      "512it [00:07, 70.26it/s]\n",
      "512it [00:06, 77.73it/s] \n",
      "512it [00:06, 81.67it/s] \n",
      "512it [00:06, 76.75it/s]\n",
      "512it [00:06, 75.23it/s]\n",
      "512it [00:06, 78.18it/s]\n",
      "512it [00:06, 74.34it/s]\n",
      "512it [00:07, 73.01it/s]\n",
      "512it [00:07, 70.18it/s]\n",
      "512it [00:06, 75.75it/s]\n",
      "512it [00:06, 73.93it/s]\n",
      "512it [00:06, 75.62it/s]\n",
      "512it [00:07, 71.62it/s]\n",
      "512it [00:07, 72.01it/s]\n",
      "512it [00:06, 74.59it/s] \n",
      "512it [00:07, 71.44it/s]\n",
      "512it [00:06, 75.41it/s]\n",
      "512it [00:07, 69.93it/s]\n",
      "512it [00:07, 69.61it/s]\n",
      "512it [00:07, 71.46it/s]\n",
      "512it [00:07, 72.09it/s]\n",
      "67it [00:00, 82.07it/s]]]\n",
      "512it [00:04, 111.26it/s]\n",
      "512it [00:05, 99.71it/s] \n",
      "512it [00:04, 109.27it/s]\n",
      "512it [00:04, 107.04it/s]\n",
      "512it [00:04, 103.08it/s]\n",
      "512it [00:04, 102.51it/s]\n",
      "512it [00:06, 84.58it/s]]\n",
      "512it [00:06, 82.69it/s] \n",
      "512it [00:06, 80.88it/s]\n",
      "512it [00:06, 80.68it/s] \n",
      "512it [00:06, 80.82it/s]\n",
      "512it [00:06, 79.47it/s]\n",
      "512it [00:06, 79.84it/s]\n",
      "512it [00:06, 79.02it/s]\n",
      "512it [00:06, 78.24it/s]\n",
      "512it [00:06, 78.10it/s]\n",
      "512it [00:06, 76.42it/s]\n",
      "512it [00:06, 75.60it/s]\n",
      "512it [00:06, 75.47it/s]\n",
      "512it [00:06, 75.53it/s]\n",
      "512it [00:06, 75.15it/s]\n",
      "512it [00:06, 74.85it/s]\n",
      "512it [00:06, 74.77it/s]\n",
      "512it [00:06, 73.43it/s]\n",
      "512it [00:07, 71.89it/s]\n",
      "512it [00:07, 71.83it/s]\n",
      "512it [00:06, 77.88it/s] \n",
      "512it [00:06, 82.40it/s]\n",
      "512it [00:06, 78.44it/s]\n",
      "512it [00:06, 75.22it/s]\n",
      "512it [00:06, 74.79it/s]\n",
      "512it [00:06, 80.24it/s]\n",
      "512it [00:07, 72.90it/s]\n",
      "512it [00:06, 77.56it/s]\n",
      "512it [00:06, 73.39it/s]\n",
      "512it [00:06, 82.49it/s]\n",
      "512it [00:06, 77.35it/s]\n",
      "512it [00:06, 73.82it/s]\n",
      "512it [00:06, 73.32it/s]\n",
      "512it [00:06, 73.98it/s]\n",
      "512it [00:06, 80.66it/s]\n",
      "512it [00:06, 78.55it/s]\n",
      "512it [00:06, 75.26it/s]\n",
      "512it [00:06, 75.76it/s]\n",
      "512it [00:07, 71.37it/s]\n",
      "512it [00:06, 75.34it/s]\n",
      "67it [00:00, 119.48it/s]\n",
      "512it [00:04, 106.56it/s]\n",
      "512it [00:04, 118.68it/s]\n",
      "512it [00:04, 113.33it/s]\n",
      "512it [00:04, 111.85it/s]\n",
      "512it [00:04, 109.09it/s]\n",
      "512it [00:04, 106.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def split_dataframe(df, chunk_size = 10000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "\n",
    "for fold in range(CFG.n_splits):#[FOLD]:#range(CFG.n_splits):\n",
    "    rows = train_folds[train_folds['fold']==fold]\n",
    "    chunks = split_dataframe(rows, CHUNK_SIZE)\n",
    "    part_size = len(chunks)//N_PART\n",
    "    last = (part+1)*part_size if part != N_PART - 1 else len(chunks)+1\n",
    "    chunks = chunks[part*part_size:last]\n",
    "    \n",
    "    N = [len(x) for x in chunks]\n",
    "    _ = Parallel(n_jobs=cpu_count())(\n",
    "        delayed(process_chunk)(x, f'tmp/{DATASET_NAME}/fold{fold}-{i}-{n}.tfrecords')\n",
    "        for i,(x,n) in enumerate(zip(chunks,N))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
